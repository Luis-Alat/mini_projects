{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1951bdb-9aca-496d-a4f4-739c298675de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lromero/mambaforge/envs/DataScience/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92db1e79-d1e8-44ee-8c85-b0572ff2c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 704019 entries, 0 to 704018\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   comment  704019 non-null  object\n",
      " 1   class    704019 non-null  int8  \n",
      "dtypes: int8(1), object(1)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "Xy_data = pd.read_feather(\"data/labeled_data_clean.feather\")\n",
    "Xy_data[\"comment\"] = Xy_data[\"comment\"].transform(list)\n",
    "\n",
    "Xy_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479914d6-aa2e-49c7-81bd-6c81592397d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    313661\n",
       "0    199718\n",
       "2    190640\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_data[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031e4474-d53e-4138-ae80-bdb69fe8587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (492813,)\n",
      "y_train shape: (492813,)\n",
      "X_test shape: (211206,)\n",
      "y_test shape: (211206,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    Xy_data = Xy_data.sample(Xy_data.shape[0], replace=False)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(Xy_data[\"comment\"],\n",
    "                                                    Xy_data[\"class\"],\n",
    "                                                    train_size=0.7)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "808aa104-ea49-4fde-a8f8-4f6a12fdff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape X_train: (492813, 27110)\n",
      "New shape X_test: (211206, 27110)\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = TfidfVectorizer(dtype = np.float32, min_df = 10)\n",
    "tfidf_model.fit(Xy_data[\"comment\"].apply(\" \".join))\n",
    "\n",
    "X_train = tfidf_model.transform(X_train.apply(\" \".join))\n",
    "X_test = tfidf_model.transform(X_test.apply(\" \".join))\n",
    "\n",
    "print(f\"New shape X_train: {X_train.shape}\")\n",
    "print(f\"New shape X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb91fa-cd0b-4e10-b2ed-e2f2d571e207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM].."
     ]
    }
   ],
   "source": [
    "clf_model = SVC(kernel=\"linear\", verbose=True) \n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f8d5d-98cc-4faf-b4cf-96160dfc554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experimental = False\n",
    "\n",
    "if run_experimental:\n",
    "\n",
    "    # Machine/deep learning parameters\n",
    "    model_parameters = {\n",
    "\n",
    "        \"svm-linear\": {\"kernel\":\"linear\"},\n",
    "        \"random-forest\": {},\n",
    "        \"xgboost\": {\"n_estimators\": 500,\n",
    "                    \"objective\": 'multi:softprob',\n",
    "                    \"num_class\": 3,\n",
    "                    \"use_label_encoder\": False,\n",
    "                    \"eval_metric\":\"mlogloss\"},\n",
    "\n",
    "    }\n",
    "\n",
    "    # Machine/deep learning options\n",
    "    model_options = {\n",
    "\n",
    "        \"svm-linear\": SVC,\n",
    "        \"random-forest\": RandomForestClassifier,\n",
    "        \"xgboost\": xgb.XGBClassifier\n",
    "\n",
    "    }\n",
    "\n",
    "    sample = 2000\n",
    "\n",
    "    # Iterate over the data sets\n",
    "    for key_data, values_data in data_options.items():\n",
    "        \n",
    "        mask_train_test = values_data[\"type\"] == \"labeled\"\n",
    "\n",
    "        if sample:\n",
    "            train_test_data = values_data[mask_train_test].sample(sample)\n",
    "        else:\n",
    "            train_test_data = values_data[mask_train_test]\n",
    "\n",
    "        # X and y to train/test later. Getting only labeled data\n",
    "        X, y = train_test_data[\"X\"], train_test_data[\"y\"]\n",
    "        y = y.transform(int).to_numpy().reshape(-1,)\n",
    "\n",
    "        # Train/Test split 80/20\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                            y,\n",
    "                                                            train_size = 0.8,\n",
    "                                                            random_state = 42)\n",
    "\n",
    "        # Removing variables no longer used and free memory\n",
    "        del X, y, mask_train_test\n",
    "        gc.collect()\n",
    "\n",
    "        # Iterate over the vectorization options\n",
    "        for key_vec, vec_func in vectorization_options.items():\n",
    "\n",
    "            # We'll use all data to fit the vectorization, not only the labeled\n",
    "            input_data_vec = vectorization_preprocessing[key_vec](values_data[\"X\"])\n",
    "            vectorization_obj_fitted = vec_func()\n",
    "            vectorization_obj_fitted.fit(input_data_vec)\n",
    "\n",
    "            # We'll only transform the labeled data\n",
    "            input_data_transform_train = vectorization_preprocessing[key_vec](X_train)\n",
    "            input_data_transform_test = vectorization_preprocessing[key_vec](X_test)\n",
    "\n",
    "            X_train_vectorized = vectorization_obj_fitted.transform(input_data_transform_train)\n",
    "            X_test_vectorized = vectorization_obj_fitted.transform(input_data_transform_test)\n",
    "\n",
    "            if vectorization_processing[key_vec] is not None:\n",
    "                X_train_vectorized = vectorization_processing[key_vec](X_train_vectorized)\n",
    "                X_test_vectorized = vectorization_processing[key_vec](X_test_vectorized)\n",
    "\n",
    "            # Iterate over the machine/deep learning options\n",
    "            for key_model, model_obj in model_options.items():\n",
    "\n",
    "                # Initializing model with the respective parameters\n",
    "                \n",
    "                model_clf = model_obj(**model_parameters[key_model])\n",
    "\n",
    "                model_clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "                y_hat = model_clf.predict(X_test_vectorized)\n",
    "                \n",
    "                report = classification_report(y_test,\n",
    "                                               y_hat,\n",
    "                                               labels=[0,1,2],\n",
    "                                               target_names=[\"Negative\",\"Neutral\",\"Positive\"])\n",
    "\n",
    "                matrix_report = confusion_matrix(y_test, y_hat, labels=[0, 1, 2])\n",
    "                \n",
    "                print(f\"data: {key_data}\")\n",
    "                print(f\"vectorization: {key_vec}\")\n",
    "                print(f\"model: {key_model}\")\n",
    "                print(report)\n",
    "                print(f\"\\n{matrix_report}\")\n",
    "                print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceee582-bef0-4947-bfb8-abe60d86eb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
