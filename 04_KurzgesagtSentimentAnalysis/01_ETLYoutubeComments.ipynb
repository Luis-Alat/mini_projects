{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85534bb2-7642-4898-953e-5ec9d11f07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import html\n",
    "import getpass\n",
    "import warnings\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from langdetect import detect, DetectorFactory\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Text, DateTime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.exc import SQLAlchemyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37eb2f4c-4c9e-4ba1-9c46-bbd949e3895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadKeyYotube():\n",
    "    \n",
    "    # Load the API key of youtube v3 found in .env\n",
    "    \n",
    "    with open(\"../.env\",\"r\") as iJSON:\n",
    "        key = json.load(iJSON)[\"keys\"][\"key_youtube\"]\n",
    "    return key\n",
    "\n",
    "def GetVideoComments(video_id:str) -> \"list(dict)\":\n",
    "\n",
    "    '''\n",
    "    This function retrieves the comment, date, user and likes of a youtube video\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    video_id: str\n",
    "        id of youtube video\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "        list(dict): List of diccionaries containing the comment, date, user and likes of the comment\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> from googleapiclient.discovery import build\n",
    "    >>> my_video = \"dGiQaabX3_o\"\n",
    "    >>> youtube = build('youtube', 'v3', developerKey=api_key) # replace by your api key\n",
    "    >>> comments = get_video_comments(my_video) \n",
    "\n",
    "    '''\n",
    "    \n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    iteration = 1\n",
    "    while True:\n",
    "        \n",
    "        if (iteration % 10) == 0:\n",
    "            print(f\"\\tPages checked: {iteration}\", end=\"\\r\")\n",
    "        \n",
    "        response = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            pageToken=next_page_token,\n",
    "            maxResults=10000\n",
    "        ).execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comment_date = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "            comment_user = item['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "            comment_likes = item['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "\n",
    "            comment_data = {\n",
    "                'comment': comment,\n",
    "                'published_date': comment_date,\n",
    "                'name': comment_user,\n",
    "                'likes': comment_likes\n",
    "            }\n",
    "            \n",
    "            comments.append(comment_data)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "            \n",
    "        iteration += 1\n",
    "    \n",
    "    print(\"\\nAll done\")\n",
    "    return comments\n",
    "\n",
    "def GetLanguage(text:str):\n",
    "    \n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"undefined\"\n",
    "\n",
    "# Defining tables found in database\n",
    "    \n",
    "class Languages(declarative_base()):\n",
    "    __tablename__ = 'languages'\n",
    "\n",
    "    # Here Integer represents SERIAL in id column\n",
    "    id_language = Column(Integer, primary_key=True, nullable=False, unique=True)\n",
    "    code = Column(String(9), nullable=False, unique=True)\n",
    "    \n",
    "class Titles(declarative_base()):\n",
    "    __tablename__ = 'titles'\n",
    "\n",
    "    id_video = Column(String(12), primary_key=True, nullable=False, unique=True)\n",
    "    title = Column(String, nullable=False)\n",
    "    \n",
    "class Users(declarative_base()):\n",
    "    __tablename__ = 'users'\n",
    "    \n",
    "    # Here Integer represents SERIAL in id column\n",
    "    id_user = Column(Integer, primary_key=True, nullable=False, unique=True)\n",
    "    name = Column(String, nullable=False)\n",
    "    \n",
    "class Comments(declarative_base()):\n",
    "    __tablename__ = 'comments'\n",
    "\n",
    "    # Here Integer represents SERIAL in id column\n",
    "    id_comment = Column(Integer, primary_key=True, nullable=False, unique=True)\n",
    "    comment = Column(Text, nullable=True)\n",
    "    published_date = Column(DateTime, nullable=True)\n",
    "    likes = Column(Integer, nullable=True)\n",
    "    id_user = Column(Integer, nullable=False)\n",
    "    id_video = Column(String, nullable=False)\n",
    "    id_language = Column(Integer, nullable=False)\n",
    "\n",
    "class DataValidator:\n",
    "    def __init__(self, engine, orm_model):\n",
    "        self.engine = engine\n",
    "        self.Session = sessionmaker(bind=self.engine, autoflush=False)\n",
    "        self.orm_model = orm_model\n",
    "    \n",
    "    def ValidateData(self, dataframe:pd.DataFrame, errors:str=\"stop\"):\n",
    "        \n",
    "        session = self.Session()\n",
    "        bad_rows = []\n",
    "        \n",
    "        for row in dataframe.itertuples():\n",
    "\n",
    "            row = row._asdict()\n",
    "            index = row.pop(\"Index\")\n",
    "                \n",
    "            try:\n",
    "                model = self.orm_model(**row)\n",
    "                session.add(model)\n",
    "                session.flush()\n",
    "                \n",
    "            except SQLAlchemyError as ErrorDataType:\n",
    "                \n",
    "                if errors == \"ignore\":\n",
    "                    bad_rows.append(index)\n",
    "                    warnings.warn(f\"Data validation failed: {ErrorDataType}\")\n",
    "                else:\n",
    "                    session.rollback()\n",
    "                    session.close()\n",
    "                    if errors == \"stop\":\n",
    "                        raise Exception(f\"Data validation failed: {ErrorDataTyper}\")\n",
    "                    else:\n",
    "                        raise ValueError(f\"Argument 'error' not valid: {errors}. Expected ['stop', 'ignore']\")\n",
    "        \n",
    "        session.rollback()\n",
    "        print(\"Done\")\n",
    "        session.close()\n",
    "        \n",
    "        return bad_rows\n",
    "    \n",
    "class InsertData:\n",
    "    def __init__(self, engine, orm_model):\n",
    "        self.engine = engine\n",
    "        self.Session = sessionmaker(bind=self.engine, autoflush=False)\n",
    "        self.orm_model = orm_model\n",
    "        \n",
    "    def Insert(self, dataframe:pd.DataFrame):\n",
    "        \n",
    "        session = self.Session()\n",
    "        \n",
    "        for row in dataframe.itertuples(index=False):\n",
    "            \n",
    "            row = row._asdict()\n",
    "            model = self.orm_model(**row)\n",
    "            session.add(model)\n",
    "            \n",
    "        session.commit()\n",
    "        session.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad25792-bec6-4b47-9af2-bb9fe0f21ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving from video: What Happened Before History? Human Origins\n",
      "\tPages checked: 210\n",
      "All done\n",
      "Comments retrieved: 20936\n",
      "Retrieving from video: The Past We Can Never Return To – The Anthropocene Reviewed\n",
      "\tPages checked: 100\n",
      "All done\n",
      "Comments retrieved: 10631\n",
      "Retrieving from video: Why Blue Whales Don't Get Cancer - Peto's Paradox\n",
      "\tPages checked: 160\n",
      "All done\n",
      "Comments retrieved: 15974\n",
      "Retrieving from video: What If We Detonated All Nuclear Bombs at Once?\n",
      "\tPages checked: 390\n",
      "All done\n",
      "Comments retrieved: 39683\n",
      "Retrieving from video: We WILL Fix Climate Change!\n",
      "\tPages checked: 250\n",
      "All done\n",
      "Comments retrieved: 25138\n",
      "Retrieving from video: Building a Marsbase is a Horrible Idea: Let's do it!\n",
      "\tPages checked: 160\n",
      "All done\n",
      "Comments retrieved: 16043\n",
      "Retrieving from video: What if We Nuke a City?\n",
      "\tPages checked: 510\n",
      "All done\n",
      "Comments retrieved: 51121\n"
     ]
    }
   ],
   "source": [
    "# Set up API key\n",
    "api_key = LoadKeyYotube()\n",
    "\n",
    "# Set up YouTube Data API client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Specify the video ID for which you want to retrieve comments\n",
    "video_names = [\"What Happened Before History? Human Origins\",\n",
    "               \"The Past We Can Never Return To – The Anthropocene Reviewed\",\n",
    "               \"Why Blue Whales Don't Get Cancer - Peto's Paradox\",\n",
    "               \"What If We Detonated All Nuclear Bombs at Once?\",\n",
    "               \"We WILL Fix Climate Change!\",\n",
    "               \"Building a Marsbase is a Horrible Idea: Let's do it!\",\n",
    "               \"What if We Nuke a City?\"]\n",
    "\n",
    "videos_id = [\"dGiQaabX3_o\",\"YbgnlkJPga4\",\n",
    "             \"1AElONvi9WQ\",\"JyECrGp-Sw8\",\n",
    "             \"LxgMdjyw8uw\",\"uqKGREZs6-w\",\n",
    "             \"5iPH-br_eJQ\"]\n",
    "\n",
    "# Call the function to retrieve comments for the specified video\n",
    "full_comment_metadata_videos = []\n",
    "for name, ID in zip(video_names, videos_id):\n",
    "    \n",
    "    print(f\"Retrieving from video: {name}\")\n",
    "    video_comments = GetVideoComments(ID)\n",
    "    full_comment_metadata_videos.append(video_comments)\n",
    "    \n",
    "    print(f\"Comments retrieved: {len(video_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffaed22-ed11-49d7-8eb3-c5a663982224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179526 entries, 0 to 179525\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   comment         179526 non-null  object\n",
      " 1   published_date  179526 non-null  object\n",
      " 2   name            179526 non-null  object\n",
      " 3   likes           179526 non-null  int64 \n",
      " 4   id_video        179526 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "video_id_df = pd.DataFrame({\"id_video\": video_names,\"title\": videos_id})\n",
    "comments_df = pd.DataFrame()\n",
    "\n",
    "# Adding id_video where the comments came from\n",
    "for comments_by_video, ID in zip(full_comment_metadata_videos, videos_id):\n",
    "    df = pd.DataFrame(comments_by_video)\n",
    "    df[\"id_video\"] = ID\n",
    "    comments_df = pd.concat([comments_df, df])\n",
    "    \n",
    "comments_df = comments_df.reset_index(drop=True).copy()\n",
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f81923da-dc2d-4c25-ad52-f5f17a66f271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179526 entries, 0 to 179525\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   comment         179526 non-null  object        \n",
      " 1   published_date  179526 non-null  datetime64[ns]\n",
      " 2   name            179526 non-null  object        \n",
      " 3   likes           179526 non-null  int64         \n",
      " 4   id_video        179526 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Casting correctly date time\n",
    "date_series = comments_df[\"published_date\"].str.replace(\"(T|Z)\", \" \", regex=True)\n",
    "date_format = pd.to_datetime(date_series, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "comments_df[\"published_date\"] = date_format\n",
    "\n",
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "801543b8-4b55-49de-8e6c-1b38a6c7ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lromero/mambaforge/envs/DataScience/lib/python3.10/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.3 s, sys: 126 ms, total: 34.4 s\n",
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Transforming HTML \"codification\" to utf-8\n",
    "map_columns_to_function = {\"comment\":html.unescape, \"name\":html.unescape}\n",
    "comments_df[[\"comment\",\"name\"]] = comments_df[[\"comment\",\"name\"]].agg(map_columns_to_function)\n",
    "\n",
    "# Emoji code patterns\n",
    "emoji_patterns = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        u\"\\U00002500-\\U00002BEF\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "\n",
    "# Non printable characters\n",
    "non_printable_patterns = re.compile(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F\\r]')\n",
    "\n",
    "# Clean emojis, html tags and detect language\n",
    "clean_text = []\n",
    "for text in comments_df[\"comment\"]:\n",
    "    clean_emojis_text = emoji_patterns.sub(r\"\", text)\n",
    "    \n",
    "    # More expensive than ReGex but more useful using BeatifulSoup for html tags\n",
    "    clean_html_text = BeautifulSoup(clean_emojis_text, \"lxml\").text\n",
    "    clean_non_print = non_printable_patterns.sub(r\" \", clean_html_text)\n",
    "    clean_text.append(clean_non_print)\n",
    "    \n",
    "comments_df[\"comment\"] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d1cd35d-ca98-439d-8c1f-0ae091ba6cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing comment number 179526\n",
      "CPU times: user 11min 26s, sys: 7.29 s, total: 11min 34s\n",
      "Wall time: 11min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Detecting language\n",
    "comment_languages = []\n",
    "for i, text in enumerate(comments_df[\"comment\"], start=1):\n",
    "    \n",
    "    print(f\"Processing comment number {i}\", end=\"\\r\")\n",
    "    \n",
    "    # langdetect doesn't work very well in short sentences. Threshold > 4\n",
    "    if len(re.split(\"\\s+\", text)) > 4:\n",
    "        language = GetLanguage(text)\n",
    "    else:\n",
    "        language = \"undefined\"\n",
    "        \n",
    "    comment_languages.append(language)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "comments_df[\"code\"] = comment_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8e814a-4f66-44e7-9b0d-7479602c7596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User postgres: postgres\n",
      "Host: localhost\n",
      "Database: youtube\n",
      "Password: ········\n"
     ]
    }
   ],
   "source": [
    "username = input(\"User postgres:\")\n",
    "host = input(\"Host:\")\n",
    "database = input(\"Database:\")\n",
    "password = getpass.getpass(\"Password:\")\n",
    "\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}/{database}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab3d6a6-3038-4229-8687-5ef882f5ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_languages = pd.DataFrame(comments_df[\"code\"].unique(), columns=[\"code\"])\n",
    "df_titles = pd.DataFrame({\"id_video\":videos_id, \"title\":video_names})\n",
    "df_users = pd.DataFrame(comments_df[\"name\"].unique(), columns=[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03195e70-8e28-4dc6-8d77-f3a12295b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating registers in table: languages\n",
      "Done\n",
      "Commiting registers in table: languages\n",
      "Done\n",
      "Validating registers in table: titles\n",
      "Done\n",
      "Commiting registers in table: titles\n",
      "Done\n",
      "Validating registers in table: users\n",
      "Done\n",
      "Commiting registers in table: users\n",
      "Done\n",
      "CPU times: user 1min 45s, sys: 7.95 s, total: 1min 53s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tables_isolated = [(\"languages\", Languages, df_languages),\n",
    "          (\"titles\", Titles, df_titles),\n",
    "          (\"users\", Users, df_users)]\n",
    "\n",
    "commit = True\n",
    "for table_name, orm_model, df in tables_isolated:\n",
    "    \n",
    "    print(f\"Validating registers in table: {table_name}\")\n",
    "    validator = DataValidator(engine, orm_model)\n",
    "    bad_rows = validator.ValidateData(df, errors=\"ignore\")\n",
    "    \n",
    "    if commit:\n",
    "        df = df.copy().drop(bad_rows, axis=0)\n",
    "        if df.shape[0] > 0:\n",
    "            print(f\"Commiting registers in table: {table_name}\")\n",
    "            insert = InsertData(engine, orm_model)\n",
    "            insert.Insert(df)\n",
    "            print(f\"Done\")\n",
    "        else:\n",
    "            print(f\"Nothing to insert in table: {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7cb9e74-835f-411c-b28b-bf411f91c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "registers_languages = pd.read_sql(\"SELECT * FROM languages\", engine)\n",
    "registers_users = pd.read_sql(\"SELECT * FROM users\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "949c9b20-6b5c-4b67-8fc9-2a70aaad30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping language of the comment and user with the id repectively\n",
    "comments_df_mapped = comments_df.copy().merge(registers_languages,\n",
    "                       how=\"left\",\n",
    "                       on=\"code\")\n",
    "\n",
    "comments_df_mapped.drop([\"code\"], axis=1, inplace=True)\n",
    "\n",
    "comments_df_mapped = comments_df_mapped.merge(registers_users,\n",
    "                        how=\"left\",\n",
    "                        on=\"name\")\n",
    "\n",
    "comments_df_mapped.drop([\"name\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f44ce35-7d79-44a8-9b62-90740a34ff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating registers in table: comments\n",
      "Done\n",
      "Commiting registers in table: comments\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "tables_no_isolated = [(\"comments\", Comments, comments_df_mapped)]\n",
    "\n",
    "commit = True\n",
    "for table_name, orm_model, df in tables_no_isolated:\n",
    "    \n",
    "    print(f\"Validating registers in table: {table_name}\")\n",
    "    validator = DataValidator(engine, orm_model)\n",
    "    bad_rows = validator.ValidateData(df, errors=\"ignore\")\n",
    "    \n",
    "    if commit:\n",
    "        df = df.copy().drop(bad_rows, axis=0)\n",
    "        if df.shape[0] > 0:\n",
    "            print(f\"Commiting registers in table: {table_name}\")\n",
    "            insert = InsertData(engine, orm_model)\n",
    "            insert.Insert(df)\n",
    "            print(f\"Done\")\n",
    "        else:\n",
    "            print(f\"Nothing to insert in table: {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce14e87d-4fc0-49ae-8935-61d53cec4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410e3db-6039-447e-8604-a674ce79466c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
