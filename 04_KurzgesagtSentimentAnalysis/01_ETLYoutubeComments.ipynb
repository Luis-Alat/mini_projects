{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85534bb2-7642-4898-953e-5ec9d11f07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from langdetect import detect, DetectorFactory\n",
    "import json\n",
    "import pandas as pd\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37eb2f4c-4c9e-4ba1-9c46-bbd949e3895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadKeyYotube():\n",
    "    \n",
    "    # Load the API key of youtube v3 found in .env\n",
    "    \n",
    "    with open(\"../.env\",\"r\") as iJSON:\n",
    "        key = json.load(iJSON)[\"keys\"][\"key_youtube\"]\n",
    "    return key\n",
    "\n",
    "def GetVideoComments(video_id:str) -> \"list(dict)\":\n",
    "\n",
    "    '''\n",
    "    This function retrieves the comment, date, user and likes of a youtube video\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    video_id: str\n",
    "        id of youtube video\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "        list(dict): List of diccionaries containing the comment, date, user and likes of the comment\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> from googleapiclient.discovery import build\n",
    "    >>> my_video = \"dGiQaabX3_o\"\n",
    "    >>> youtube = build('youtube', 'v3', developerKey=api_key) # replace by your api key\n",
    "    >>> comments = get_video_comments(my_video) \n",
    "\n",
    "    '''\n",
    "    \n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    iteration = 1\n",
    "    while True:\n",
    "        \n",
    "        if (iteration % 10) == 0:\n",
    "            print(f\"\\tPages checked: {iteration}\", end=\"\\r\")\n",
    "        \n",
    "        response = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            pageToken=next_page_token,\n",
    "            maxResults=10000\n",
    "        ).execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comment_date = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "            comment_user = item['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "            comment_likes = item['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "\n",
    "            comment_data = {\n",
    "                'comment': comment,\n",
    "                'date': comment_date,\n",
    "                'user': comment_user,\n",
    "                'likes': comment_likes\n",
    "            }\n",
    "            \n",
    "            comments.append(comment_data)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "            \n",
    "        iteration += 1\n",
    "    \n",
    "    print(\"\\nAll done\")\n",
    "    return comments\n",
    "\n",
    "def GetLanguage(text:str):\n",
    "    \n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"undefined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad25792-bec6-4b47-9af2-bb9fe0f21ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving from video: What Happened Before History? Human Origins\n",
      "\tPages checked: 210\n",
      "All done\n",
      "Comments retrieved: 20935\n",
      "Retrieving from video: The Past We Can Never Return To – The Anthropocene Reviewed\n",
      "\tPages checked: 100\n",
      "All done\n",
      "Comments retrieved: 10631\n",
      "Retrieving from video: Why Blue Whales Don't Get Cancer - Peto's Paradox\n",
      "\tPages checked: 160\n",
      "All done\n",
      "Comments retrieved: 15971\n",
      "Retrieving from video: What If We Detonated All Nuclear Bombs at Once?\n",
      "\tPages checked: 390\n",
      "All done\n",
      "Comments retrieved: 39682\n",
      "Retrieving from video: We WILL Fix Climate Change!\n",
      "\tPages checked: 250\n",
      "All done\n",
      "Comments retrieved: 25130\n",
      "Retrieving from video: Building a Marsbase is a Horrible Idea: Let's do it!\n",
      "\tPages checked: 160\n",
      "All done\n",
      "Comments retrieved: 16042\n",
      "Retrieving from video: What if We Nuke a City?\n",
      "\tPages checked: 510\n",
      "All done\n",
      "Comments retrieved: 51118\n"
     ]
    }
   ],
   "source": [
    "# Set up API key\n",
    "api_key = LoadKeyYotube()\n",
    "\n",
    "# Set up YouTube Data API client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Specify the video ID for which you want to retrieve comments\n",
    "video_names = [\"What Happened Before History? Human Origins\",\n",
    "               \"The Past We Can Never Return To – The Anthropocene Reviewed\",\n",
    "               \"Why Blue Whales Don't Get Cancer - Peto's Paradox\",\n",
    "               \"What If We Detonated All Nuclear Bombs at Once?\",\n",
    "               \"We WILL Fix Climate Change!\",\n",
    "               \"Building a Marsbase is a Horrible Idea: Let's do it!\",\n",
    "               \"What if We Nuke a City?\"]\n",
    "\n",
    "videos_id = [\"dGiQaabX3_o\",\"YbgnlkJPga4\",\n",
    "             \"1AElONvi9WQ\",\"JyECrGp-Sw8\",\n",
    "             \"LxgMdjyw8uw\",\"uqKGREZs6-w\",\n",
    "             \"5iPH-br_eJQ\"]\n",
    "\n",
    "# Call the function to retrieve comments for the specified video\n",
    "full_comment_metadata_videos = []\n",
    "for name, ID in zip(video_names, videos_id):\n",
    "    \n",
    "    print(f\"Retrieving from video: {name}\")\n",
    "    video_comments = GetVideoComments(ID)\n",
    "    full_comment_metadata_videos.append(video_comments)\n",
    "    \n",
    "    print(f\"Comments retrieved: {len(video_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffaed22-ed11-49d7-8eb3-c5a663982224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179509 entries, 0 to 179508\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   comment   179509 non-null  object\n",
      " 1   date      179509 non-null  object\n",
      " 2   user      179509 non-null  object\n",
      " 3   likes     179509 non-null  int64 \n",
      " 4   id_video  179509 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "video_id_df = pd.DataFrame({\"id_video\": video_names,\"title_video\": videos_id})\n",
    "comments_df = pd.DataFrame()\n",
    "\n",
    "# Adding id_video where the comments came from\n",
    "for comments_by_video, ID in zip(full_comment_metadata_videos, videos_id):\n",
    "    df = pd.DataFrame(comments_by_video)\n",
    "    df[\"id_video\"] = ID\n",
    "    comments_df = pd.concat([comments_df, df])\n",
    "    \n",
    "comments_df = comments_df.reset_index(drop=True).copy()\n",
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f81923da-dc2d-4c25-ad52-f5f17a66f271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179509 entries, 0 to 179508\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   comment   179509 non-null  object        \n",
      " 1   date      179509 non-null  datetime64[ns]\n",
      " 2   user      179509 non-null  object        \n",
      " 3   likes     179509 non-null  int64         \n",
      " 4   id_video  179509 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Casting correctly date time\n",
    "date_series = comments_df[\"date\"].str.replace(\"(T|Z)\", \" \", regex=True)\n",
    "date_format = pd.to_datetime(date_series, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "comments_df[\"date\"] = date_format\n",
    "\n",
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "801543b8-4b55-49de-8e6c-1b38a6c7ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lromero/mambaforge/envs/DataScience/lib/python3.10/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 55.9 ms, total: 30.2 s\n",
      "Wall time: 30.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Transforming HTML \"codification\" to utf-8\n",
    "map_columns_to_function = {\"comment\":html.unescape, \"user\":html.unescape}\n",
    "comments_df[[\"comment\",\"user\"]] = comments_df[[\"comment\",\"user\"]].agg(map_columns_to_function)\n",
    "\n",
    "# Emoji code patterns\n",
    "emoji_patterns = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        u\"\\U00002500-\\U00002BEF\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "\n",
    "# Non printable characters\n",
    "non_printable_patterns = re.compile(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F\\r]')\n",
    "\n",
    "# Clean emojis, html tags and detect language\n",
    "clean_text = []\n",
    "for text in comments_df[\"comment\"]:\n",
    "    clean_emojis_text = emoji_patterns.sub(r\"\", text)\n",
    "    \n",
    "    # More expensive than ReGex but more useful using BeatifulSoup for html tags\n",
    "    clean_html_text = BeautifulSoup(clean_emojis_text, \"lxml\").text\n",
    "    clean_non_print = non_printable_patterns.sub(r\" \", clean_html_text)\n",
    "    clean_text.append(clean_non_print)\n",
    "    \n",
    "comments_df[\"comment\"] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1cd35d-ca98-439d-8c1f-0ae091ba6cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing comment number 179508\n",
      "CPU times: user 10min 46s, sys: 5.19 s, total: 10min 51s\n",
      "Wall time: 10min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Detecting language\n",
    "comment_languages = []\n",
    "for i, text in enumerate(comments_df[\"comment\"], start=1):\n",
    "    \n",
    "    print(f\"Processing comment number {i}\", end=\"\\r\")\n",
    "    \n",
    "    # langdetect doesn't work very well in short sentences. Threshold > 4\n",
    "    if len(re.split(\"\\s+\", text)) > 4:\n",
    "        language = GetLanguage(text)\n",
    "    else:\n",
    "        language = \"undefined\"\n",
    "        \n",
    "    comment_languages.append(language)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "comments_df[\"language\"] = comment_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5af497e9-1b42-4e4b-bf6d-80bc43e4456a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment', 'date', 'user', 'likes', 'id_video', 'language'], dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95047cc0-95d6-4f93-8b07-85e7170f5747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 11, 11, 11, 11, 11, 11]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(id) for id in comments_df[\"id_video\"].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12e33d-8d85-4621-80d8-04ab8705c5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
