{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c13fb92-14cb-4c76-bbc8-ce554dd6b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29148396-fff6-470e-98f7-ba8888608712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapMaps:\n",
    "    \n",
    "    '''\n",
    "    This class is made for scrapping google maps\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "        driver_path:str\n",
    "            Path to find and load webdriver for Chrome browser\n",
    "            \n",
    "        sleep_time:int; default=2\n",
    "            seconds to wait between each selenium execution on browser\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, driver_path:str, sleep_time:int=2):\n",
    "        \n",
    "        self.driver = webdriver.Chrome(service=Service(driver_path))\n",
    "        self.sleep_time = sleep_time\n",
    "        \n",
    "    def SearchByUrl(self, url:str):\n",
    "        \n",
    "        # This function use the url to make a google maps search\n",
    "        \n",
    "        print(f\"Seaching by url: {url}\")\n",
    "        self.driver.get(url)\n",
    "        time.sleep(self.sleep_time)\n",
    "        \n",
    "    def ScrollDownResults(self, xpath_element_results:str, class_name_results:str):\n",
    "        \n",
    "        '''\n",
    "        This function scroll down in the results section found in the left of google maps\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "            xpath_element_results: str\n",
    "                xpath path to manipulate the results section and scroll down\n",
    "            \n",
    "            class_name_results: str\n",
    "                class name to identify the number of results thrown by google maps found inside\n",
    "                the xpath_element_results\n",
    "        '''\n",
    "        \n",
    "        print(\"Scrolling down...\")\n",
    "        n_before_scroll = len(self.driver.find_elements(By.CLASS_NAME, class_name_results))\n",
    "        element_to_scroll = self.driver.find_element(By.XPATH, xpath_element_results)\n",
    "        \n",
    "        # Scroll down\n",
    "        self.driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", element_to_scroll)\n",
    "        time.sleep(self.sleep_time)\n",
    "        \n",
    "        n_after_scroll = len(self.driver.find_elements(By.CLASS_NAME, class_name_results))\n",
    "        \n",
    "        # Scrolling until there are no more results\n",
    "        while n_before_scroll != n_after_scroll:\n",
    "            \n",
    "            n_before_scroll = int(n_after_scroll)\n",
    "            \n",
    "            element_to_scroll = self.driver.find_element(By.XPATH, xpath_element_results)\n",
    "            self.driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", element_to_scroll)\n",
    "            time.sleep(self.sleep_time)\n",
    "            \n",
    "            n_after_scroll = len(self.driver.find_elements(By.CLASS_NAME, class_name_results))\n",
    "        \n",
    "        print(\"No more results found\")\n",
    "        \n",
    "    def GetResultsLocation(self, class_name:str, \n",
    "                           loc_attribute:str=\"href\", name_attribute:str=\"aria-label\") -> dict:\n",
    "        \n",
    "        '''\n",
    "        This function get latitude, longitude and name of the results got by google maps\n",
    "        '''\n",
    "        \n",
    "        # Retrieving all available results on maps (results)\n",
    "        places = self.driver.find_elements(By.CLASS_NAME, class_name)\n",
    "        longitude = []\n",
    "        latitude = []\n",
    "        name = []\n",
    "        \n",
    "        for place in places:\n",
    "            \n",
    "            # Filter in the url latitude and longitude (closed between the !3d and !4d characters)\n",
    "            geographic_loc = re.findall(\"\\!3d(-?\\d+\\.\\d+)\\!4d(-?\\d+\\.\\d+)\",\n",
    "                                        place.get_attribute(loc_attribute))[0]\n",
    "            \n",
    "            latitude.append(geographic_loc[0])\n",
    "            longitude.append(geographic_loc[1])\n",
    "            name.append(place.get_attribute(name_attribute))\n",
    "            \n",
    "        return {\"latitude\":latitude, \"longitude\":longitude, \"name\":name}\n",
    "            \n",
    "    def GetResultsReviews(self, parent_class_name:str, \n",
    "                          class_name:str, name_attribute:str=\"aria-label\") -> dict:\n",
    "        \n",
    "        # Retrieving all available results on maps (reviews)\n",
    "        reviews = self.driver.find_elements(By.CLASS_NAME, parent_class_name)\n",
    "        n_comments = []\n",
    "        rating = []\n",
    "        \n",
    "        for review in reviews:\n",
    "            \n",
    "            check_review = review.find_elements(By.CLASS_NAME, class_name)\n",
    "            \n",
    "            if len(check_review) > 0:\n",
    "        \n",
    "                review_cleaned = check_review[0].get_attribute(name_attribute) \n",
    "                review_cleaned = re.findall(\"(\\d\\.\\d|\\s+\\d+)\", review_cleaned)\n",
    "        \n",
    "                rating.append(review_cleaned[0])\n",
    "                n_comments.append(review_cleaned[1].strip())\n",
    "        \n",
    "            else:\n",
    "                rating.append(np.NaN)\n",
    "                n_comments.append(np.NaN)\n",
    "                \n",
    "        return {\"comments\":n_comments, \"rating\": rating}\n",
    "    \n",
    "    def Close(self):\n",
    "        self.driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423822f1-e4be-4bf4-aa86-c8d3fc3a55cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertMarks(text:str):\n",
    "    \n",
    "    '''\n",
    "    Convert accent marks in spanish to its base form\n",
    "    '''\n",
    "    \n",
    "    base_form_vowels = {\"á\":\"a\",\"é\":\"e\",\"í\":\"i\",\"ó\":\"o\",\"ú\":\"u\"}\n",
    "    new_string = \"\"\n",
    "    \n",
    "    for character in text:\n",
    "        \n",
    "        if character in base_form_vowels.keys():\n",
    "            new_string += base_form_vowels[character]\n",
    "        else:\n",
    "            new_string += character\n",
    "    \n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac8cc79-b431-45e5-9577-e1df4dd085cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Delegaciones from a web table\n",
    "delegaciones_cdmx = pd.read_html(\"https://micodigopostal.org/ciudad-de-mexico/\")\n",
    "delegaciones_cdmx = delegaciones_cdmx[0].drop(labels=4).values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8a2395-2e42-4441-ab9e-676e1e5e8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing zip codes and metadata about zip codes from delegaciones\n",
    "delegaciones_cdmx_clean = [delegacion.lower().replace(\" \",\"-\") for delegacion in delegaciones_cdmx]\n",
    "\n",
    "# Replacing accent marks by its base form\n",
    "for i, delegacion in enumerate(delegaciones_cdmx_clean):\n",
    "    delegaciones_cdmx_clean[i] = ConvertMarks(delegacion).replace(\".\",\"\")\n",
    "    \n",
    "# Creating url and retrieving from web zip codes in mexico city\n",
    "cdmx_address = pd.DataFrame()\n",
    "for url in delegaciones_cdmx_clean:\n",
    "    web_page = f\"https://micodigopostal.org/ciudad-de-mexico/{url}/\"\n",
    "    cdmx_address = pd.concat([cdmx_address, pd.read_html(web_page)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2f2707-73a8-4917-9dbc-95a82f2fb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning unnecesary rows using the pattern \"adsbygoogle\"\n",
    "mask = map(lambda x: bool(re.findall(\"adsbygoogle\", x)), cdmx_address[\"Asentamiento▼\"])\n",
    "mask = pd.Series(list(mask))\n",
    "cdmx_address = cdmx_address[~mask.values].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a1fea0-6ce6-4b21-adc6-84434cfdae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = cdmx_address[\"Código Postal\"].values\n",
    "zip_code.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb69f29-46f6-4aff-8e02-210ac5154754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seaching by url: https://www.google.com/maps/search/oxxo+01000/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 72.29711055755615 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01010/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 40.18050479888916 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01020/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 58.6889283657074 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01030/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 69.52186560630798 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01030/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 46.42599296569824 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01040/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 68.55495476722717 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01049/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 52.60365390777588 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01050/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 52.92119550704956 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01060/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 86.53276133537292 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01060/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 31.525137901306152 secs\n",
      "\t10 iterations have been completed. Waiting 5 seconds\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01070/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 40.580697536468506 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01080/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 44.429205894470215 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01089/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 23.29226016998291 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01090/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moxxo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.google.com/maps/search/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m query\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mgoogle_maps_scrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSearchByUrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m google_maps_scrapper\u001b[38;5;241m.\u001b[39mScrollDownResults(xpath_element_results, class_name_results)\n\u001b[1;32m     23\u001b[0m oxxo_loc \u001b[38;5;241m=\u001b[39m google_maps_scrapper\u001b[38;5;241m.\u001b[39mGetResultsLocation(class_name \u001b[38;5;241m=\u001b[39m class_name_results)\n",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m, in \u001b[0;36mScrapMaps.SearchByUrl\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeaching by url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Defining paths to scrap on maps\n",
    "web_driver_path = \"../../../Descargas/chromedriver_linux64/chromedriver\"\n",
    "\n",
    "xpath_element_results = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]'\n",
    "class_name_results =  'hfpxzc'\n",
    "\n",
    "parent_class_name_reviews = \"UaQhfb fontBodyMedium\".replace(\" \", \".\")\n",
    "class_name_reviews = \"ZkP5Je\"\n",
    "\n",
    "# Initialize scraping object\n",
    "google_maps_scrapper = ScrapMaps(web_driver_path, 3)\n",
    "\n",
    "oxxo_df = pd.DataFrame()\n",
    "start_block = time.time()\n",
    "\n",
    "for i, zp in enumerate(zip_code):\n",
    "    \n",
    "    start = time.time()\n",
    "    query = f\"oxxo {zp}\"\n",
    "    url = \"https://www.google.com/maps/search/\" + query.replace(\" \", \"+\") + \"/\"\n",
    "    \n",
    "    google_maps_scrapper.SearchByUrl(url)\n",
    "    google_maps_scrapper.ScrollDownResults(xpath_element_results, class_name_results)\n",
    "    oxxo_loc = google_maps_scrapper.GetResultsLocation(class_name = class_name_results)\n",
    "    oxxo_rev = google_maps_scrapper.GetResultsReviews(parent_class_name = parent_class_name_reviews, \n",
    "                                                  class_name=class_name_reviews)\n",
    "\n",
    "    oxxo_current_zip = pd.merge(left=pd.DataFrame(oxxo_loc), right=pd.DataFrame(oxxo_rev), \n",
    "                  right_index=True, left_index=True)\n",
    "    \n",
    "    oxxo_current_zip[\"cp\"] = zp\n",
    "    \n",
    "    oxxo_df = pd.concat([oxxo_df, oxxo_current_zip])\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"This iter took {end - start} secs\")\n",
    "    \n",
    "    # Hopefully google dont ban me\n",
    "    if ((i + 1) % 10) == 0:\n",
    "        \n",
    "        end_block = time.time()\n",
    "        print(\"\\t10 iterations have been completed. Waiting 5 seconds\")\n",
    "        print(f\"\\tThis block took {end_block - start_block} secs\")\n",
    "        start_block = time.time()\n",
    "        \n",
    "        oxxo_df.to_csv(\"oxxo_coordinates.csv\", index=False)\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "    if ((i + 1) % 100) == 0:\n",
    "        print(\"\\t100 iterations have been completed\")\n",
    "        \n",
    "google_maps_scrapper.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86670e68-6027-429a-9fd6-bc764d15c0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
