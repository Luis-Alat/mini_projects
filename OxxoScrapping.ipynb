{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee61c250-54f2-4653-812c-41aa01e47b5e",
   "metadata": {},
   "source": [
    "# Web Scrapping: oxxo stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae02c70-46b5-4648-b84a-52892cdce6a4",
   "metadata": {},
   "source": [
    "This notebook is created to scrape the localization and some other information about Oxxo stores (which are very popular in Mexico) by using Google Maps.\n",
    "\n",
    "Unfortunately, the official website of the store does not have the latest information and is not more user-friendly than Google Maps. For that reason, I chose maps as a better alternative.\n",
    "\n",
    "On the other hand, the localization of the stores is only intended to be done for the Mexico City area (or CDMX in Spanish). However, in theory, the code (at least the web scraping section) should work for whatever search you wish.\n",
    "\n",
    "Finally, there are comments throughout the notebook if you want to know more about the logic of the process. However, there is no intention for it to be a full tutorial. But, if it's useful for you, feel free to check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c13fb92-14cb-4c76-bbc8-ce554dd6b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29148396-fff6-470e-98f7-ba8888608712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapMaps:\n",
    "    \n",
    "    '''\n",
    "    This class was created to do web scrapping on google maps searches\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "        driver_path:str\n",
    "            Path to find and load webdriver for Chrome browser\n",
    "            \n",
    "        sleep_time:int; default=2\n",
    "            seconds to wait between each selenium execution on browser\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, driver_path:str, sleep_time:int=2):\n",
    "        \n",
    "        self.driver = webdriver.Chrome(service=Service(driver_path))\n",
    "        self.sleep_time = sleep_time\n",
    "    \n",
    "    def DefineSearchStatus(self, class_name_results, class_name_partial):\n",
    "        \n",
    "        # This function checks if the search query returned a possible partial match, zero results\n",
    "        # or multiples results\n",
    "        \n",
    "        # Status if the search query returns a partial match (False means no partial match)\n",
    "        self.partial_match_status = False\n",
    "        self.zero_results_status = False\n",
    "                \n",
    "        # Check if only one result was returned. It could be \"partial match\" status\n",
    "        results = self.driver.find_elements(By.CLASS_NAME, class_name_results)\n",
    "        if len(results) == 1:\n",
    "            \n",
    "            # Check if there is a partial message on web page\n",
    "            check_partial_match = len(self.driver.find_elements(By.CLASS_NAME, class_name_partial))\n",
    "            self.partial_match_status = True if check_partial_match else False\n",
    "            \n",
    "        if len(results) == 0:\n",
    "            self.zero_results_status = True\n",
    "    \n",
    "    def SearchByUrl(self, url:str) -> bool:\n",
    "        \n",
    "        # This function use the url to do a search on google maps\n",
    "        \n",
    "        self.url = url\n",
    "        \n",
    "        print(f\"Seaching by url: {self.url}\")\n",
    "        self.driver.get(self.url)\n",
    "        time.sleep(self.sleep_time)\n",
    "        \n",
    "    def ScrollDownResults(self, xpath_element_results:str, class_name_results:str):\n",
    "        \n",
    "        '''\n",
    "        This function scroll down in the results section found in the left of google maps\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "            xpath_element_results: str\n",
    "                xpath path to manipulate the results section and scroll down\n",
    "            \n",
    "            class_name_results: str\n",
    "                class name to identify the number of results thrown by google maps found inside\n",
    "                the xpath_element_results \n",
    "            \n",
    "        '''\n",
    "        \n",
    "        print(\"Scrolling down...\")\n",
    "        n_before_scroll = len(self.driver.find_elements(By.CLASS_NAME, class_name_results))\n",
    "        element_to_scroll = self.driver.find_element(By.XPATH, xpath_element_results)\n",
    "        \n",
    "        # Scroll down\n",
    "        self.driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", element_to_scroll)\n",
    "        time.sleep(self.sleep_time)\n",
    "        \n",
    "        n_after_scroll = len(self.driver.find_elements(By.CLASS_NAME, class_name_results))\n",
    "        \n",
    "        # Scrolling until there are no new results\n",
    "        while n_before_scroll != n_after_scroll:\n",
    "            \n",
    "            n_before_scroll = int(n_after_scroll)\n",
    "            \n",
    "            element_to_scroll = self.driver.find_element(By.XPATH, xpath_element_results)\n",
    "            self.driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", element_to_scroll)\n",
    "            time.sleep(self.sleep_time)\n",
    "            \n",
    "            n_after_scroll = len(self.driver.find_elements(By.CLASS_NAME, class_name_results))\n",
    "        \n",
    "        print(\"No more results found\")\n",
    "        \n",
    "    def GetResultsLocation(self, class_name:str, loc_attribute:str=\"href\",\n",
    "                           name_attribute:str=\"aria-label\") -> dict:\n",
    "        \n",
    "        '''\n",
    "        This function get latitude, longitude and name of the results got by google maps\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        class_name: str\n",
    "            Common class name (HTML) of the results thrown by google maps\n",
    "            \n",
    "        loc_attribute: str\n",
    "            Common attribute name (HTML) to find the url where is incrusted the\n",
    "            latitude and longitude values. loc_attribute must be found in the class_name\n",
    "            class\n",
    "                \n",
    "        name_attribute: str\n",
    "            Common attribute name (HTML) to find the name of the result. name_attribute must\n",
    "            be found in the class_name class\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        \n",
    "        dict: latitude, longitude and name of the results by google maps\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # Retrieving all available results on maps (results)\n",
    "        places = self.driver.find_elements(By.CLASS_NAME, class_name)\n",
    "        longitude = []\n",
    "        latitude = []\n",
    "        name = []\n",
    "        \n",
    "        for place in places:\n",
    "            \n",
    "            # Filter in the url latitude and longitude (closed between the !3d and !4d characters)\n",
    "            geographic_loc = re.findall(\"\\!3d(-?\\d+\\.\\d+)\\!4d(-?\\d+\\.\\d+)\",\n",
    "                                        place.get_attribute(loc_attribute))[0]\n",
    "            \n",
    "            latitude.append(geographic_loc[0])\n",
    "            longitude.append(geographic_loc[1])\n",
    "            name.append(place.get_attribute(name_attribute))\n",
    "            \n",
    "        return {\"latitude\":latitude, \"longitude\":longitude, \"name\":name}\n",
    "            \n",
    "    def GetResultsReviews(self, parent_class_name:str, \n",
    "                          class_name:str, name_attribute:str=\"aria-label\") -> dict:\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        This function retrieves the general metrics (reviews) of the google map search\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        parent_class_name: str\n",
    "            Common class name of the parent node where would be expected the HMTL of the review.\n",
    "            Not all the results on google maps have reviews and this argument is thought to\n",
    "            deal with that\n",
    "        \n",
    "        class_name: str\n",
    "            Common class name of the HTML where is located the review info\n",
    "            \n",
    "        name_attribute: str\n",
    "            common attribute name to find the info about the review. name_attribute is expected\n",
    "            to be found in class_name\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        \n",
    "        dict: number of comments and general rating of the results of the search\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # Retrieving all available results on maps (reviews)\n",
    "        reviews = self.driver.find_elements(By.CLASS_NAME, parent_class_name)\n",
    "        n_comments = []\n",
    "        rating = []\n",
    "        \n",
    "        for review in reviews:\n",
    "            \n",
    "            check_review = review.find_elements(By.CLASS_NAME, class_name)\n",
    "            \n",
    "            if len(check_review) > 0:\n",
    "        \n",
    "                review_cleaned = check_review[0].get_attribute(name_attribute) \n",
    "                review_cleaned = re.findall(\"(\\d\\.\\d|\\s+\\d+)\", review_cleaned)\n",
    "        \n",
    "                rating.append(review_cleaned[0])\n",
    "                n_comments.append(review_cleaned[1].strip())\n",
    "        \n",
    "            else:\n",
    "                rating.append(np.NaN)\n",
    "                n_comments.append(np.NaN)\n",
    "                \n",
    "        return {\"comments\":n_comments, \"rating\": rating}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423822f1-e4be-4bf4-aa86-c8d3fc3a55cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertMarks(text:str):\n",
    "    \n",
    "    '''\n",
    "    Converts vowel accents found in Spanish to their base form\n",
    "    '''\n",
    "    \n",
    "    base_form_vowels = {\"á\":\"a\",\"é\":\"e\",\"í\":\"i\",\"ó\":\"o\",\"ú\":\"u\"}\n",
    "    new_string = \"\"\n",
    "    \n",
    "    for character in text:\n",
    "        \n",
    "        if character in base_form_vowels.keys():\n",
    "            new_string += base_form_vowels[character]\n",
    "        else:\n",
    "            new_string += character\n",
    "    \n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac8cc79-b431-45e5-9577-e1df4dd085cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Delegaciones from a web table\n",
    "delegaciones_cdmx = pd.read_html(\"https://micodigopostal.org/ciudad-de-mexico/\")\n",
    "delegaciones_cdmx = delegaciones_cdmx[0].drop(labels=4).values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8a2395-2e42-4441-ab9e-676e1e5e8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing zip codes and metadata about zip codes from delegaciones\n",
    "delegaciones_cdmx_clean = [delegacion.lower().replace(\" \",\"-\") for delegacion in delegaciones_cdmx]\n",
    "\n",
    "# Replacing accent marks by its base form\n",
    "for i, delegacion in enumerate(delegaciones_cdmx_clean):\n",
    "    delegaciones_cdmx_clean[i] = ConvertMarks(delegacion).replace(\".\",\"\")\n",
    "    \n",
    "# Creating url and retrieving from web zip codes in mexico city\n",
    "cdmx_address = pd.DataFrame()\n",
    "for url in delegaciones_cdmx_clean:\n",
    "    web_page = f\"https://micodigopostal.org/ciudad-de-mexico/{url}/\"\n",
    "    cdmx_address = pd.concat([cdmx_address, pd.read_html(web_page)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2f2707-73a8-4917-9dbc-95a82f2fb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning unnecesary rows using the pattern \"adsbygoogle\"\n",
    "mask = map(lambda x: bool(re.findall(\"adsbygoogle\", x)), cdmx_address[\"Asentamiento▼\"])\n",
    "mask = pd.Series(list(mask))\n",
    "cdmx_address = cdmx_address[~mask.values].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a1fea0-6ce6-4b21-adc6-84434cfdae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = cdmx_address[\"Código Postal\"].values\n",
    "zip_code.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb69f29-46f6-4aff-8e02-210ac5154754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seaching by url: https://www.google.com/maps/search/oxxo+01000/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 72.66801071166992 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01010/\n",
      "Scrolling down...\n",
      "No more results found\n",
      "This iter took 51.33474087715149 secs\n",
      "Seaching by url: https://www.google.com/maps/search/oxxo+01020/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moxxo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.google.com/maps/search/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m query\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mgoogle_maps_scrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSearchByUrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m google_maps_scrapper\u001b[38;5;241m.\u001b[39mScrollDownResults(xpath_element_results, class_name_results)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Defining if there are zero results or partial match\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 49\u001b[0m, in \u001b[0;36mScrapMaps.SearchByUrl\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m url\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeaching by url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msleep_time)\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:449\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:438\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    436\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:290\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    288\u001b[0m data \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdump_json(params)\n\u001b[1;32m    289\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:311\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    308\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 311\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/DataScience/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Defining paths to scrap on maps\n",
    "web_driver_path = \"../../../Descargas/chromedriver_linux64/chromedriver\"\n",
    "\n",
    "# HTML elements on google maps when searching. Box element, individual results and partial match\n",
    "# repectively\n",
    "xpath_element_results = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]'\n",
    "class_name_results =  'hfpxzc'\n",
    "class_name_partial_coincidence = \"L5xkq Hk4XGb\".replace(\" \", \".\")\n",
    "\n",
    "# HTML for each result on maps and general reviews of those respectively\n",
    "parent_class_name_reviews = \"UaQhfb fontBodyMedium\".replace(\" \", \".\")\n",
    "class_name_reviews = \"ZkP5Je\"\n",
    "\n",
    "# Initialize scraping object\n",
    "google_maps_scrapper = ScrapMaps(web_driver_path, 3)\n",
    "\n",
    "oxxo_df = pd.DataFrame()\n",
    "start_block = time.time()\n",
    "\n",
    "for i, zp in enumerate(zip_code):\n",
    "    \n",
    "    start = time.time()\n",
    "    query = f\"oxxo {zp}\"\n",
    "    url = \"https://www.google.com/maps/search/\" + query.replace(\" \", \"+\") + \"/\"\n",
    "    \n",
    "    google_maps_scrapper.SearchByUrl(url)\n",
    "    google_maps_scrapper.ScrollDownResults(xpath_element_results, class_name_results)\n",
    "    \n",
    "    # Defining if there are zero results or partial match\n",
    "    google_maps_scrapper.DefineSearchStatus(class_name_results, class_name_partial_coincidence)\n",
    "    \n",
    "    if google_maps_scrapper.zero_results_status or google_maps_scrapper.partial_match_status:\n",
    "        print(f\"Zero results or partial match was found. Skiping {google_maps_scrapper.url}\")\n",
    "        continue\n",
    "    \n",
    "    oxxo_loc = google_maps_scrapper.GetResultsLocation(class_name = class_name_results)\n",
    "    oxxo_rev = google_maps_scrapper.GetResultsReviews(parent_class_name = parent_class_name_reviews, \n",
    "                                                  class_name=class_name_reviews)\n",
    "\n",
    "    oxxo_current_zip = pd.merge(left=pd.DataFrame(oxxo_loc), right=pd.DataFrame(oxxo_rev), \n",
    "                  right_index=True, left_index=True)\n",
    "    \n",
    "    oxxo_current_zip[\"cp\"] = zp\n",
    "    \n",
    "    oxxo_df = pd.concat([oxxo_df, oxxo_current_zip])\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"This iter took {end - start} secs\")\n",
    "    \n",
    "    # Hopefully google dont ban me\n",
    "    if ((i + 1) % 10) == 0:\n",
    "        \n",
    "        end_block = time.time()\n",
    "        print(\"\\t10 iterations have been completed. Waiting 5 seconds\")\n",
    "        print(f\"\\tThis block took {end_block - start_block} secs\")\n",
    "        start_block = time.time()\n",
    "        \n",
    "        oxxo_df.to_csv(\"oxxo_coordinates.csv\", index=False)\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "    if ((i + 1) % 100) == 0:\n",
    "        print(\"\\t100 iterations have been completed\")\n",
    "        \n",
    "google_maps_scrapper.driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
